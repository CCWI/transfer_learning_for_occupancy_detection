{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb41d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2.6.0'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.Logger import Logger\n",
    "from utils.Experiments import Data, DataDomainwise, Settings, TrainOnce, PretrainingFinetuning, DomainAdversarialLearning\n",
    "from utils.DataPreparation import prepare_data\n",
    "from utils.Evaluation import evaluate\n",
    "\n",
    "from Models.CDBLSTM import CDBLSTM\n",
    "from Models.DACDBLSTM import DACDBLSTM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"../../3_Results/Experiments_1day_20/\"\n",
    "os.mkdir(project_dir) if not os.path.exists(project_dir) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(\"../../3_Results\", \"Experiments_1day_20\", \"logfile.log\")\n",
    "logger.activate_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = \"../../1_Data/datasets.h5\"\n",
    "\n",
    "target_dataset_names = ['Office_A', 'Office_B', 'Home', 'Candanedo', 'Stjelja']\n",
    "source_dataset_names = ['Office_A', 'Office_B', 'Home', 'Candanedo', 'Stjelja', 'Simulated']\n",
    "\n",
    "# Note that the Stjelja dataset was not published along with this script and needs to be removed to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6801a2d",
   "metadata": {},
   "source": [
    "#### Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_days = 1 # number of days from target data used for training\n",
    "window_size = 30  # length of each input sample passed to the model\n",
    "trials = 20       # number of repetitions for each experiment\n",
    "epochs = 1000     # maximum number of epochs if early stopping does not occur   \n",
    "initial_seed = 0  # seed value of first trial; seeds are then incremented by one with each trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f93cf",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ae247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "\n",
    "    for target in target_dataset_names:\n",
    "        for source in source_dataset_names:\n",
    "            if target == source:\n",
    "                continue\n",
    "                \n",
    "            # Preparation\n",
    "            subproject = source + \"->\" + target\n",
    "            project_subdir = project_dir + subproject + \"/\"\n",
    "            os.mkdir(project_subdir) if not os.path.exists(project_subdir) else None\n",
    "            print(subproject)\n",
    "            \n",
    "            dataset_src = pd.read_hdf(hdf5_file, source)\n",
    "            dataset_tar = pd.read_hdf(hdf5_file, target)\n",
    "\n",
    "            x_train_raw, x_test_raw, y_train_raw, y_test_raw = train_test_split(dataset_tar['CO2'].values, \n",
    "                                                                         dataset_tar['Occupancy'].values, \n",
    "                                                                         test_size=0.2, shuffle=False)\n",
    "            # For testing, we only use the last 20% of each dataset, which were held out during hyperparameter tuning\n",
    "            print(\"Preparing test data:\") # Test data for all transfer methods\n",
    "            x_test, y_test = prepare_data(x_test_raw, y_test_raw, window_size=window_size)\n",
    "            \n",
    "\n",
    "            # Target Only Training\n",
    "            print(\"Target Only Training...\")\n",
    "            x_train, y_train, x_val, y_val, _, _ = prepare_data(x_train_raw, y_train_raw, \n",
    "                                                                splitAt=[training_days*1440, training_days*1440+1440], \n",
    "                                                                window_size=window_size)\n",
    "\n",
    "            path = project_subdir + \"targetOnly\"\n",
    "            data = Data(x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            TrainOnce(data, settings).run()\n",
    "\n",
    "            # Domain-Adversarial Learning\n",
    "            print(\"Domain-Adversarial Learning (Domain Classifier Position 1)...\")\n",
    "            x_train, y_train, x_val, y_val, _, _ = prepare_data(x_train_raw, y_train_raw,\n",
    "                                                                [dataset_src['CO2'].values], [dataset_src['Occupancy'].values],\n",
    "                                                                splitAt=[training_days*1440, training_days*1440+1440], \n",
    "                                                                window_size=window_size)\n",
    "            path = project_subdir + \"DA_Pos1\"\n",
    "            data = Data(x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "            settings = Settings(path, DACDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            DomainAdversarialLearning(data, settings, domain_clf_position=1, save_as='DA_Pos1').run()\n",
    "\n",
    "            print(\"Domain-Adversarial Learning (Domain Classifier Position 2)...\")\n",
    "            path = project_subdir + \"DA_Pos2\"\n",
    "            settings = Settings(path, DACDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            DomainAdversarialLearning(data, settings, domain_clf_position=2, save_as='DA_Pos2').run()\n",
    "\n",
    "            # Pretraining & Fine-Tuning\n",
    "            print(\"Pretraining & Fine-Tuning...\")\n",
    "            x_tar_train, y_tar_train, x_tar_val, y_tar_val, _, _ = \\\n",
    "                                        prepare_data(x_train_raw, y_train_raw,\n",
    "                                                     splitAt=[training_days*1440, training_days*1440+1440], \n",
    "                                                     window_size=window_size)\n",
    "            x_src_train, y_src_train, x_src_val, y_src_val = \\\n",
    "                                        prepare_data(dataset_src['CO2'].values, dataset_src['Occupancy'].values, \n",
    "                                                        splitAt=0.8, window_size=window_size) # use 20% for validation during pretraining\n",
    "            path = project_subdir + \"pretrainingFineTuning\"\n",
    "            data = DataDomainwise(x_tar_train, y_tar_train, x_tar_val, y_tar_val, \n",
    "                                  x_src_train, y_src_train, x_src_val, y_src_val, x_test, y_test)\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            PretrainingFinetuning(data, settings).run()\n",
    "\n",
    "            print(\"Pretraining & Fine-Tuning (with source and target data)...\")\n",
    "            path = project_subdir + \"pretrainingFineTuning_src_and_target\"\n",
    "            x_fine_tune = np.append(x_tar_train, x_src_train[:(int(len(x_tar_train)))], axis=0)\n",
    "            y_fine_tune = np.append(y_tar_train, y_src_train[:(int(len(y_tar_train)))], axis=0)\n",
    "            print(\"Fine-Tune on:\", np.shape(x_fine_tune), np.shape(y_fine_tune))\n",
    "            data_plus = DataDomainwise(x_fine_tune, y_fine_tune, x_tar_val, y_tar_val, x_src_train, y_src_train, x_src_val, y_src_val, x_test, y_test)\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            PretrainingFinetuning(data_plus, settings, \n",
    "                                  save_as = [\"pretrainingFineTuning_src_tar_pre\", \n",
    "                                             \"pretrainingFineTuning_src_tar_fine\"]).run()\n",
    "\n",
    "            # Layer-Freezing\n",
    "            print(\"Layer Freezing (freeze CNN)...\")\n",
    "            path = project_subdir + \"layerFreezing_CNN\"\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            PretrainingFinetuning(data, settings, freeze_first_n_layers=4, # 4 = freeze CNN\n",
    "                                  save_as = [\"layerFreezing_CNN_pre\", \n",
    "                                             \"layerFreezing_CNN\"]).run()\n",
    "\n",
    "            print(\"Layer Freezing (freeze CNN+BLSTM)...\")\n",
    "            path = project_subdir + \"layerFreezing_CNN_BLSTM\"\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            PretrainingFinetuning(data, settings, freeze_first_n_layers=7, # 7 = freeze CNN+BLSTM\n",
    "                                  save_as = [\"layerFreezing_CNN_BLSTM_pre\", \n",
    "                                             \"layerFreezing_CNN_BLSTM\"]).run()\n",
    "\n",
    "run_experiments()\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
