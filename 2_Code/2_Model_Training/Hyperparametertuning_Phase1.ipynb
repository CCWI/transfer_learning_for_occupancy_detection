{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7c53d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "from csv import writer\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "tzInfo = pytz.timezone('Europe/Paris')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Dense, Conv1D, Flatten, Dropout, \\\n",
    "                                    MaxPooling1D, Bidirectional, LSTM, Input, \\\n",
    "                                    Activation\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "import keras_tuner as kt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Models.HyperCDBLSTM import HyperCDBLSTM\n",
    "from Models.KerasTunerHyperModel_Phase1 import KerasTunerHyperModel\n",
    "\n",
    "from utils.Logger import Logger\n",
    "from utils.DataPreparation import walk_forward, prepare_data\n",
    "from utils.Evaluation import evaluate, plot_training, plot_accuracy, plot_loss\n",
    "from utils.Experiments import Data, DataDomainwise, Settings, TrainOnce, PretrainingFinetuning, DomainAdversarialLearning, set_seed\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3ca8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing directory found.\n",
      "Logging to ../../3_Results/Hyperparametertuning/Phase_1/logfile.log\n"
     ]
    }
   ],
   "source": [
    "project_dir = \"../../3_Results/Hyperparametertuning\"\n",
    "project_name = \"Phase_1\"\n",
    "project_path = project_dir + \"/\" + project_name + \"/\"\n",
    "if not os.path.exists(project_path):\n",
    "    os.mkdir(project_path)\n",
    "    os.mkdir(project_path + \"tensorboard/\")  \n",
    "    os.mkdir(project_path + \"keras_tuner/\")  \n",
    "    os.mkdir(project_path + \"evaluations/\")  \n",
    "else:\n",
    "    print(\"Existing directory found.\")\n",
    "if os.path.exists(project_path + \"logfile.log\"):\n",
    "    os.rename(project_path + \"logfile.log\", project_path + \"logfile_{}.log\".format(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")))\n",
    "logger = Logger(project_dir, project_name, \"logfile.log\")\n",
    "logger.activate_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf940f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([15, 30, 60, 'raw'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data samples from pickle file\n",
    "with open('../../1_Data/data_samples_for_hyperparametertuning.pkl', 'rb') as file:\n",
    "    data_samples = pickle.load(file)\n",
    "\n",
    "data_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b028ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp, oracle):\n",
    "\n",
    "    #seed = len(oracle._tried_so_far) + 1\n",
    "    seed = len([t for t in os.listdir(project_path + 'keras_tuner') if 'trial_' in t])\n",
    "    print(\"seed:\", seed)\n",
    "    batch_size     = hp.Choice('batch_size', KerasTunerHyperModel.choices['batch_size'])\n",
    "    window_size    = hp.Choice('window_size', KerasTunerHyperModel.choices['window_size'])\n",
    "    optimizer      = hp.Choice('optimizer', KerasTunerHyperModel.choices['optimizer'])\n",
    "    stateful_blstm = hp.Boolean('stateful_blstm', default=False)\n",
    "    \n",
    "    max_number_of_convolutions = 2\n",
    "    max_number_of_blstm_layers = 4\n",
    "    max_number_of_dense_layers = 4\n",
    "    number_of_convolutions = hp.Int(\"number_of_convolutions\", min_value=1, max_value=max_number_of_convolutions, step=1)\n",
    "    number_of_blstm_layers = hp.Int(\"number_of_blstm_layers\", min_value=1, max_value=max_number_of_blstm_layers, step=1)\n",
    "    number_of_dense_layers = hp.Int(\"number_of_dense_layers\", min_value=1, max_value=max_number_of_dense_layers, step=1)\n",
    "    \n",
    "    print(\"window_size: {}, batch_size: {}, optimizer: {}, stateful_blstm: {}\".format(\n",
    "        window_size, batch_size, optimizer, stateful_blstm))\n",
    "    print(\"convolutions: {}, blstm layers: {}, dense layers: {}\".format(\n",
    "        number_of_convolutions, number_of_blstm_layers, number_of_dense_layers))\n",
    "    \n",
    "    def next_layer(n_previous, rule, step, minimum):\n",
    "        \"\"\"To reduce complexity this function returns n, the number of neurons/cells etc. in a subsequent layer \n",
    "            based on the previous layer and a rule. There are three alternatives: \n",
    "            Subsequent layers are allowed to have the same, half or minimum n.\"\"\"\n",
    "        if n_previous == minimum:\n",
    "            return minimum\n",
    "        if rule == \"same\":\n",
    "            return n_previous\n",
    "        if rule == \"half\":\n",
    "            return math.ceil(n_previous/2/step)*step\n",
    "        if rule == \"min\":\n",
    "            return minimum\n",
    "    \n",
    "    filters = []\n",
    "    kernel_sizes = []\n",
    "    filters.append(hp.Int(f\"conv_filters_1\", min_value=50, max_value=200, step=50))\n",
    "    kernel_sizes.append(hp.Choice(f\"kernel_size_1\", [3, 5])) # 3x3 or 5x5\n",
    "    for i in range(2, number_of_convolutions + 1):\n",
    "        filters.append(hp.Int(f\"conv_filters_{i}\", min_value=50, max_value=200, step=50, parent_name=\"number_of_convolutions\", parent_values=[j for j in range(i, max_number_of_convolutions+1)]))\n",
    "        kernel_sizes.append(hp.Choice(f\"kernel_size_{i}\", [3, 5], parent_name=\"number_of_convolutions\", parent_values=[j for j in range(i, max_number_of_convolutions+1)])) # 3x3 or 5x5\n",
    "    print(\"filters:\", filters)\n",
    "    print(\"kernel sizes:\", kernel_sizes)\n",
    "    \n",
    "    lstm_cells = []\n",
    "    lstm_cells.append(hp.Int(f\"lstm_cells_1\", min_value=50, max_value=500, step=50))\n",
    "    for i in range(2, number_of_blstm_layers + 1):\n",
    "        choice = hp.Choice(f\"lstm_cells_{i}\", [\"same\", \"half\", \"min\"], parent_name=\"number_of_blstm_layers\", parent_values=[j for j in range(i, max_number_of_blstm_layers+1)])\n",
    "        lstm_cells.append(next_layer(lstm_cells[-1], choice, 50, 50))\n",
    "    print(\"lstm cells:\", lstm_cells)\n",
    "        \n",
    "    dropout_rates = []\n",
    "    dense_neurons = []\n",
    "    dense_neurons.append(hp.Int(f\"dense_neurons_1\", min_value=100, max_value=500, step=100))\n",
    "    dropout_rates.append(hp.Float(f\"dropout_rate_1\", min_value=0.1, max_value=0.5, step=0.2))\n",
    "    for i in range(2, number_of_dense_layers + 1):\n",
    "        choice_neurons = hp.Choice(f\"dense_neurons_{i}\", [\"same\", \"half\", \"min\"], parent_name=\"number_of_dense_layers\", parent_values=[j for j in range(i, max_number_of_dense_layers+1)])\n",
    "        choice_dropout = hp.Choice(f\"dropout_rate_{i}\", [\"same\", \"half\", \"min\"], parent_name=\"number_of_dense_layers\", parent_values=[j for j in range(i, max_number_of_dense_layers+1)])\n",
    "        if i <= number_of_dense_layers:\n",
    "            dense_neurons.append(next_layer(dense_neurons[-1], choice_neurons, 100, 100))\n",
    "            dropout_rates.append(next_layer(dropout_rates[-1], choice_dropout, 0.3, 0.1))\n",
    "    dropout_rates = [round(r, 1) for r in dropout_rates]\n",
    "    print(\"dense neurons\", dense_neurons)\n",
    "    print(\"dropout rates:\", dropout_rates)\n",
    "    \n",
    "    print(\"building model...\")\n",
    "    model = HyperCDBLSTM(classes=2, features=1, domains=1, \n",
    "                         optimizer=optimizer, batch_size=batch_size, window_size=window_size, seed=seed, \n",
    "                         stateful_blstm=stateful_blstm, filters=filters, kernel_sizes=kernel_sizes,\n",
    "                         lstm_cells=lstm_cells, dropout_rates=dropout_rates, dense_neurons=dense_neurons)\n",
    "    print(\"model built\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a675cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "        objective=kt.Objective(\"Cohens Kappa\", \"max\"),\n",
    "        max_trials=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d192d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = KerasTunerHyperModel(\n",
    "    data_samples = data_samples,\n",
    "    hypermodel=(lambda hp: build_model(hp, oracle)),\n",
    "    oracle=oracle,\n",
    "    overwrite=False,\n",
    "    directory=project_path,\n",
    "    project_name='keras_tuner'\n",
    ")\n",
    "tuner.objective=kt.Objective(\"Cohens Kappa\", direction=\"max\"),\n",
    "tuner.directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "018bef3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1000 Complete [00h 01m 47s]\n",
      "Cohens Kappa: 0.3744660720401437\n",
      "\n",
      "Best Cohens Kappa So Far: 0.6477687095498647\n",
      "Total elapsed time: 12h 55m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now(tz=tzInfo))\n",
    "tuner.search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
