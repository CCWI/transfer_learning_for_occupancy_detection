{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7c53d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "from csv import writer\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "tzInfo = pytz.timezone('Europe/Paris')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Dense, Conv1D, Flatten, Dropout, \\\n",
    "                                    MaxPooling1D, Bidirectional, LSTM, Input, \\\n",
    "                                    Activation\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "import keras_tuner as kt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Models.HyperDACDBLSTM import HyperDACDBLSTM\n",
    "from Models.KerasTunerHyperModel_Phase2 import KerasTunerHyperModel\n",
    "\n",
    "from utils.Logger import Logger\n",
    "from utils.DataPreparation import walk_forward, prepare_data\n",
    "from utils.Evaluation import evaluate, plot_training, plot_accuracy, plot_loss\n",
    "from utils.Experiments import Data, DataDomainwise, Settings, TrainOnce, PretrainingFinetuning, DomainAdversarialLearning, set_seed\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3ca8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"../../3_Results/Hyperparametertuning\"\n",
    "project_name = \"Phase_2\"\n",
    "project_path = project_dir + \"/\" + project_name + \"/\"\n",
    "if not os.path.exists(project_path):\n",
    "    os.mkdir(project_path)\n",
    "    os.mkdir(project_path + \"tensorboard/\")  \n",
    "    os.mkdir(project_path + \"keras_tuner/\")  \n",
    "    os.mkdir(project_path + \"evaluations/\")  \n",
    "else:\n",
    "    print(\"Existing directory found.\")\n",
    "if os.path.exists(project_path + \"logfile.log\"):\n",
    "    os.rename(project_path + \"logfile.log\", project_path + \"logfile_{}.log\".format(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")))\n",
    "logger = Logger(project_dir, project_name, \"logfile.log\")\n",
    "logger.activate_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf940f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data samples from pickle file\n",
    "with open('../../1_Data/data_samples_for_hyperparametertuning.pkl', 'rb') as file:\n",
    "    data_samples = pickle.load(file)\n",
    "\n",
    "data_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b028ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp, oracle):\n",
    "\n",
    "    #seed = len(oracle._tried_so_far) + 1\n",
    "    seed = len([t for t in os.listdir(project_path + 'keras_tuner') if 'trial_' in t])\n",
    "    print(\"seed:\", seed)\n",
    "    max_number_of_branched_dense_layers = 2\n",
    "    number_of_branched_dense_layers = hp.Int(\"number_of_branched_dense_layers\", min_value=1, \n",
    "                                             max_value=max_number_of_branched_dense_layers, step=1)\n",
    "    \n",
    "    print(\"number of branched dense layers: {}\".format(number_of_branched_dense_layers))\n",
    "    \n",
    "    def next_layer(n_previous, rule, step, minimum):\n",
    "        \"\"\"To reduce complexity this function returns n, the number of neurons/cells etc. in a subsequent layer \n",
    "            based on the previous layer and a rule. There are three alternatives: \n",
    "            Subsequent layers are allowed to have the same, half or minimum n.\"\"\"\n",
    "        if n_previous == minimum:\n",
    "            return minimum\n",
    "        if rule == \"same\":\n",
    "            return n_previous\n",
    "        if rule == \"half\":\n",
    "            return math.ceil(n_previous/2/step)*step\n",
    "        if rule == \"min\":\n",
    "            return minimum\n",
    "    \n",
    "    branched_dropout_rates = []\n",
    "    branched_dense_neurons = []\n",
    "    # first layers' values are selected from the range of defined values\n",
    "    if number_of_branched_dense_layers > 0:\n",
    "        branched_dense_neurons.append(hp.Int(f\"branched_dense_neurons_1\",  min_value=50, max_value=500, step=50, parent_name=\"number_of_branched_dense_layers\", parent_values=[j for j in range(1, max_number_of_branched_dense_layers+1)]))\n",
    "        branched_dropout_rates.append(hp.Float(f\"branched_dropout_rate_1\", min_value=0.1, max_value=0.5, step=0.2, parent_name=\"number_of_branched_dense_layers\", parent_values=[j for j in range(1, max_number_of_branched_dense_layers+1)]))\n",
    "    # further layers are assigned half/same as their preceeding layer or the minimum\n",
    "    for i in range(2, number_of_branched_dense_layers + 1):\n",
    "        choice_neurons = hp.Choice(f\"branched_dense_neurons_{i}\", [\"same\", \"half\", \"min\"], parent_name=\"number_of_branched_dense_layers\", parent_values=[j for j in range(i, max_number_of_branched_dense_layers+1)])\n",
    "        choice_dropout = hp.Choice(f\"branched_dropout_rate_{i}\", [\"same\", \"half\", \"min\"], parent_name=\"number_of_branched_dense_layers\", parent_values=[j for j in range(i, max_number_of_branched_dense_layers+1)])\n",
    "        if i <= number_of_branched_dense_layers:\n",
    "            branched_dense_neurons.append(next_layer(branched_dense_neurons[-1], choice_neurons, 100, 100))\n",
    "            branched_dropout_rates.append(next_layer(branched_dropout_rates[-1], choice_dropout, 0.3, 0.1))\n",
    "    branched_dropout_rates = [round(r, 1) for r in branched_dropout_rates]\n",
    "    print(\"branched dense neurons\", branched_dense_neurons)\n",
    "    print(\"branched dropout rates:\", branched_dropout_rates)\n",
    "    \n",
    "    print(\"building model...\")\n",
    "    model = HyperDACDBLSTM(classes=2, features=1, domains=2, seed=seed, \n",
    "                           domain_clf_neurons=branched_dense_neurons, domain_clf_dropout_rates=branched_dropout_rates)\n",
    "    print(\"model built\")\n",
    "    print(model.model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a675cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "    objective=kt.Objective(\"Cohens Kappa\", \"max\"),\n",
    "    max_trials=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d192d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = KerasTunerHyperModel(\n",
    "    data_samples = data_samples,\n",
    "    hypermodel=(lambda hp: build_model(hp, oracle)),\n",
    "    oracle=oracle,\n",
    "    overwrite=False,\n",
    "    directory=project_path,\n",
    "    project_name='keras_tuner'\n",
    ")\n",
    "tuner.objective=kt.Objective(\"Cohens Kappa\", direction=\"max\"),\n",
    "tuner.directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "169dcdab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "number_of_branched_dense_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': None}\n",
      "branched_dense_neurons_1 (Int)\n",
      "{'default': None, 'conditions': [{'class_name': 'Parent', 'config': {'name': 'number_of_branched_dense_layers', 'values': [1, 2]}}], 'min_value': 50, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "branched_dropout_rate_1 (Float)\n",
      "{'default': 0.1, 'conditions': [{'class_name': 'Parent', 'config': {'name': 'number_of_branched_dense_layers', 'values': [1, 2]}}], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.2, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018bef3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(datetime.now(tz=tzInfo))\n",
    "tuner.search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
