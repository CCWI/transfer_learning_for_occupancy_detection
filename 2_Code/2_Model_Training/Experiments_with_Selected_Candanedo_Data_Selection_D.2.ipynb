{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb41d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from utils.Logger import Logger\n",
    "from utils.Experiments import Data, DataDomainwise, Settings, TrainOnce, PretrainingFinetuning, DomainAdversarialLearning\n",
    "from utils.DataPreparation import prepare_data\n",
    "from utils.Evaluation import evaluate\n",
    "\n",
    "from Models.CDBLSTM import CDBLSTM\n",
    "from Models.DACDBLSTM import DACDBLSTM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f6e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"../../3_Results/Experiments_1day_20/\"\n",
    "os.mkdir(project_dir) if not os.path.exists(project_dir) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd5e86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ../../3_Results/Experiments_1day_20/logfile_with_selected_candanedo_data_S2.log\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(\"../../3_Results\", \"Experiments_1day_20\", \"logfile_with_selected_candanedo_data_S2.log\")\n",
    "logger.activate_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69f50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = \"../../1_Data/datasets.h5\"\n",
    "\n",
    "target_dataset_names = ['Office_A', 'Office_B', 'Home', 'Stjelja']\n",
    "source_dataset_names = ['Candanedo_Selected_S1']\n",
    "\n",
    "# Note that the Stjelja dataset was not published along with this script and needs to be removed to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55889e14",
   "metadata": {},
   "source": [
    "#### Select only reliable sections of the Candanedo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4405ad7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no train-test split applied\n",
      "train: (6546, 30, 1) (6546, 1)\n",
      "6546 training samples\n",
      "data normalized to range [0, 1]\n",
      "train: (6528, 30, 1) (6528, 1)\n",
      "(6528, 30, 1)\n",
      "(6528, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_hdf(hdf5_file, 'Candanedo')\n",
    "\n",
    "# remove unexplainable behavior\n",
    "df = df[df.Day != '2015-02-12']\n",
    "df = df[df.Day != '2015-02-16']\n",
    "df = df[df.Day != '2015-02-17']\n",
    "\n",
    "# remove slowly decaying CO2 despite occupancy\n",
    "df = df[(df.Day != '2015-02-03') | (df.Time < datetime.time(11, 23)) | (df.Time > datetime.time(13, 10))]   \n",
    "df = df[(df.Day != '2015-02-03') | (df.Time < datetime.time(16, 50)) | (df.Time > datetime.time(18, 13))]   \n",
    "df = df[(df.Day != '2015-02-05') | (df.Time < datetime.time(16, 49)) | (df.Time > datetime.time(18,  5))]   \n",
    "df = df[(df.Day != '2015-02-06') | (df.Time < datetime.time(12, 35)) | (df.Time > datetime.time(12, 54))]   \n",
    "df = df[(df.Day != '2015-02-06') | (df.Time < datetime.time(16, 59)) | (df.Time > datetime.time(18,  7))]  \n",
    "df = df[(df.Day != '2015-02-09') | (df.Time < datetime.time(12,  4)) | (df.Time > datetime.time(13, 12))]  \n",
    "df = df[(df.Day != '2015-02-09') | (df.Time < datetime.time(17, 24)) | (df.Time > datetime.time(18,  4))]  \n",
    "df = df[(df.Day != '2015-02-13') | (df.Time < datetime.time(11, 21)) | (df.Time > datetime.time(13,  1))]  \n",
    "df = df[(df.Day != '2015-02-13') | (df.Time < datetime.time(17, 10)) | (df.Time > datetime.time(18,  6))]  \n",
    "\n",
    "# prepare data\n",
    "x, y = prepare_data(df['CO2'].values, df['Occupancy'].values, splitAt=None, window_size=30)\n",
    "print(np.shape(x))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b10428",
   "metadata": {},
   "source": [
    "#### Use 80% for source training, 20% for source validaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d12d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_src_train: (4275, 30, 1)\n",
      "y_src_train: (4275, 1)\n",
      "x_src_val: (2253, 30, 1)\n",
      "y_src_val: (2253, 1)\n"
     ]
    }
   ],
   "source": [
    "x_src_train = x[:4275]\n",
    "x_src_val = x[4275:]\n",
    "y_src_train = y[:4275]\n",
    "y_src_val = y[4275:]\n",
    "print(\"x_src_train:\", np.shape(x_src_train))\n",
    "print(\"y_src_train:\", np.shape(y_src_train))\n",
    "print(\"x_src_val:\", np.shape(x_src_val))\n",
    "print(\"y_src_val:\", np.shape(y_src_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdf9b2",
   "metadata": {},
   "source": [
    "#### Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b131182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_days = 1 # number of days from target data used for training\n",
    "window_size = 30  # length of each input sample passed to the model\n",
    "trials = 20       # number of repetitions for each experiment\n",
    "epochs = 1000     # maximum number of epochs if early stopping does not occur   \n",
    "initial_seed = 0  # seed value of first trial; seeds are then incremented by one with each trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2f93cf",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ae247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "\n",
    "    for target in target_dataset_names:\n",
    "        for source in source_dataset_names:\n",
    "            if target == source:\n",
    "                continue\n",
    "                \n",
    "            # Preparation\n",
    "            subproject = source + \"->\" + target\n",
    "            project_subdir = project_dir + subproject + \"/\"\n",
    "            os.mkdir(project_subdir) if not os.path.exists(project_subdir) else None\n",
    "            print(subproject)\n",
    "            \n",
    "            dataset_tar = pd.read_hdf(hdf5_file, target)\n",
    "\n",
    "            x_train_raw, x_test_raw, y_train_raw, y_test_raw = train_test_split(dataset_tar['CO2'].values, \n",
    "                                                                         dataset_tar['Occupancy'].values, \n",
    "                                                                         test_size=0.2, shuffle=False)\n",
    "            # For testing, we only use the last 20% of each dataset, which were held out during hyperparameter tuning\n",
    "            print(\"Preparing test data:\") # Test data for all transfer methods\n",
    "            x_test, y_test = prepare_data(x_test_raw, y_test_raw, window_size=window_size)\n",
    "            \n",
    "\n",
    "            # Target Only Training\n",
    "            print(\"Target Only Training...\")\n",
    "            x_train, y_train, x_val, y_val, _, _ = prepare_data(x_train_raw, y_train_raw, \n",
    "                                                                splitAt=[training_days*1440, training_days*1440+1440], \n",
    "                                                                window_size=window_size)\n",
    "\n",
    "            path = project_subdir + \"targetOnly\"\n",
    "            data = Data(x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            TrainOnce(data, settings).run()\n",
    "\n",
    "            # Domain-Adversarial Learning\n",
    "            print(\"Domain-Adversarial Learning (Domain Classifier Position 1)...\")\n",
    "            domain_labels = np.concatenate((np.zeros(len(y_train)).reshape(-1, 1), np.ones(len(y_src_train)).reshape(-1, 1)), axis=0)\n",
    "            y_train_DA = (np.concatenate((y_train, y_src_train), axis=0), domain_labels)\n",
    "            x_train_DA = np.concatenate((x_train, x_src_train), axis=0)\n",
    "            y_val_DA   = (y_val, np.zeros(len(y_val)).reshape(-1, 1))\n",
    "            x_val_DA   = x_val      \n",
    "            print(np.shape(y_train_DA), np.shape(x_train_DA))\n",
    "            print(np.shape(y_val_DA), np.shape(x_val_DA))\n",
    "            path = project_subdir + \"DA_Pos1\"\n",
    "            data = Data(x_train_DA, y_train_DA, x_val_DA, y_val_DA, x_test, y_test)\n",
    "            settings = Settings(path, DACDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            DomainAdversarialLearning(data, settings, domain_clf_position=1, save_as='DA_Pos1').run()\n",
    "\n",
    "            print(\"Domain-Adversarial Learning (Domain Classifier Position 2)...\")\n",
    "            path = project_subdir + \"DA_Pos2\"\n",
    "            settings = Settings(path, DACDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            DomainAdversarialLearning(data, settings, domain_clf_position=2, save_as='DA_Pos2').run()\n",
    "\n",
    "            # Pretraining & Fine-Tuning\n",
    "            print(\"Pretraining & Fine-Tuning...\")\n",
    "            x_tar_train, y_tar_train, x_tar_val, y_tar_val, _, _ = \\\n",
    "                                        prepare_data(x_train_raw, y_train_raw,\n",
    "                                                     splitAt=[training_days*1440, training_days*1440+1440], \n",
    "                                                     window_size=window_size)\n",
    "            path = project_subdir + \"pretrainingFineTuning\"\n",
    "            data = DataDomainwise(x_tar_train, y_tar_train, x_tar_val, y_tar_val, \n",
    "                                  x_src_train, y_src_train, x_src_val, y_src_val, x_test, y_test)\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            PretrainingFinetuning(data, settings).run()\n",
    "\n",
    "            print(\"Pretraining & Fine-Tuning (with source and target data)...\")\n",
    "            path = project_subdir + \"pretrainingFineTuning_src_and_target\"\n",
    "            x_fine_tune = np.append(x_tar_train, x_src_train[:(int(len(x_tar_train)))], axis=0)\n",
    "            y_fine_tune = np.append(y_tar_train, y_src_train[:(int(len(y_tar_train)))], axis=0)\n",
    "            print(\"Fine-Tune on:\", np.shape(x_fine_tune), np.shape(y_fine_tune))\n",
    "            data_plus = DataDomainwise(x_fine_tune, y_fine_tune, x_tar_val, y_tar_val, x_src_train, y_src_train, x_src_val, y_src_val, x_test, y_test)\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            PretrainingFinetuning(data_plus, settings, \n",
    "                                  save_as = [\"pretrainingFineTuning_src_tar_pre\", \n",
    "                                             \"pretrainingFineTuning_src_tar_fine\"]).run()\n",
    "\n",
    "            # Layer-Freezing\n",
    "            print(\"Layer Freezing (freeze CNN)...\")\n",
    "            path = project_subdir + \"layerFreezing_CNN\"\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            PretrainingFinetuning(data, settings, freeze_first_n_layers=4, # 4 = freeze CNN\n",
    "                                  save_as = [\"layerFreezing_CNN_pre\", \n",
    "                                             \"layerFreezing_CNN\"]).run()\n",
    "\n",
    "            print(\"Layer Freezing (freeze CNN+BLSTM)...\")\n",
    "            path = project_subdir + \"layerFreezing_CNN_BLSTM\"\n",
    "            settings = Settings(path, CDBLSTM, trials=trials, epochs=epochs, verbose=2, initial_seed=initial_seed)\n",
    "            PretrainingFinetuning(data, settings, freeze_first_n_layers=7, # 7 = freeze CNN+BLSTM\n",
    "                                  save_as = [\"layerFreezing_CNN_BLSTM_pre\", \n",
    "                                             \"layerFreezing_CNN_BLSTM\"]).run()\n",
    "\n",
    "run_experiments()\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
